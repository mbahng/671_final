{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11740, 349)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from preprocess import preprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(\"data\", \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(\"data\", \"test.csv\"))\n",
    "train_data.dropna(inplace=True)\n",
    "X, y = train_data.drop([\"price\"], axis=1), train_data[\"price\"]\n",
    "y = y.to_numpy().astype(int)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_test = test_data\n",
    "\n",
    "X_train = preprocess(X_train).to_numpy().astype(float)\n",
    "X_val = preprocess(X_val).to_numpy().astype(float)\n",
    "X_test = preprocess(X_test)\n",
    "\n",
    "# scale\n",
    "scaler =  RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1238, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1411, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1238, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1411, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1238, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1411, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1238, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1411, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1238, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1411, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1238, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1411, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1238, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1411, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1238, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1411, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1238, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1411, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1238, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1411, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1238, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1411, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1721, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/muchang/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1516, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/muchang/Desktop/other/671_final/XGboost.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi3t/home/muchang/Desktop/other/671_final/XGboost.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m ada_clf \u001b[39m=\u001b[39m AdaBoostClassifier(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi3t/home/muchang/Desktop/other/671_final/XGboost.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     estimator\u001b[39m=\u001b[39mDecisionTreeClassifier()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi3t/home/muchang/Desktop/other/671_final/XGboost.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi3t/home/muchang/Desktop/other/671_final/XGboost.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m gscv \u001b[39m=\u001b[39m GridSearchCV(ada_clf, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bi3t/home/muchang/Desktop/other/671_final/XGboost.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m gscv\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi3t/home/muchang/Desktop/other/671_final/XGboost.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# ada_clf = gscv.best_estimator_\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi3t/home/muchang/Desktop/other/671_final/XGboost.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# ada_test_accuracy = ada_clf.score(X_val, y_val)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi3t/home/muchang/Desktop/other/671_final/XGboost.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# print(\"Adaboost Test Accuracy:\", ada_test_accuracy)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    734\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py:171\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    168\u001b[0m sample_weight[zero_weight_mask] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m    170\u001b[0m \u001b[39m# Boosting step\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost(\n\u001b[1;32m    172\u001b[0m     iboost, X, y, sample_weight, random_state\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    175\u001b[0m \u001b[39m# Early termination\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py:579\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[39mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 579\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[1;32m    581\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[1;32m    582\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py:588\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[1;32m    586\u001b[0m estimator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m--> 588\u001b[0m estimator\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[1;32m    590\u001b[0m y_predict_proba \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    592\u001b[0m \u001b[39mif\u001b[39;00m iboost \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    960\u001b[0m         X,\n\u001b[1;32m    961\u001b[0m         y,\n\u001b[1;32m    962\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    963\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [10, 30, 50, 70],\n",
    "    'learning_rate' : [0.01, 0.03, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "# Adaboost with DecisionTree as base estimator\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier()\n",
    ")\n",
    "\n",
    "gscv = GridSearchCV(ada_clf, param_grid, cv=5, scoring=\"f1\")\n",
    "gscv.fit(X_train, y_train)\n",
    "ada_clf = gscv.best_estimator_\n",
    "# ada_test_accuracy = ada_clf.score(X_val, y_val)\n",
    "# print(\"Adaboost Test Accuracy:\", ada_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=0.01, n_estimators=10;, score=0.494 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=10;, score=0.487 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=10;, score=0.465 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=10;, score=0.482 total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=10;, score=0.492 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.03, n_estimators=10;, score=0.500 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.03, n_estimators=10;, score=0.501 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=30;, score=0.499 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=30;, score=0.469 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=30;, score=0.492 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.03, n_estimators=10;, score=0.488 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=30;, score=0.497 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.03, n_estimators=10;, score=0.467 total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.03, n_estimators=10;, score=0.495 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=50;, score=0.487 total time=   2.7s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=50;, score=0.506 total time=   2.8s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=30;, score=0.501 total time=   2.7s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=50;, score=0.496 total time=   3.2s\n",
      "[CV 1/5] END learning_rate=0.03, n_estimators=30;, score=0.517 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.03, n_estimators=30;, score=0.518 total time=   1.7s\n",
      "[CV 4/5] END learning_rate=0.03, n_estimators=30;, score=0.498 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.03, n_estimators=30;, score=0.489 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.03, n_estimators=30;, score=0.506 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=50;, score=0.500 total time=   3.9s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=10;, score=0.508 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=50;, score=0.511 total time=   4.4s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=10;, score=0.515 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=10;, score=0.514 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.03, n_estimators=50;, score=0.508 total time=   2.8s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=10;, score=0.505 total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=10;, score=0.495 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=70;, score=0.504 total time=   5.2s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=70;, score=0.487 total time=   5.2s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=70;, score=0.509 total time=   5.3s\n",
      "[CV 1/5] END learning_rate=0.03, n_estimators=50;, score=0.526 total time=   3.7s\n",
      "[CV 5/5] END learning_rate=0.03, n_estimators=50;, score=0.503 total time=   2.9s\n",
      "[CV 3/5] END learning_rate=0.03, n_estimators=50;, score=0.519 total time=   3.8s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=70;, score=0.506 total time=   6.1s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=30;, score=0.516 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.03, n_estimators=50;, score=0.505 total time=   4.5s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=30;, score=0.517 total time=   2.2s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=30;, score=0.526 total time=   2.3s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=70;, score=0.500 total time=   6.8s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=30;, score=0.532 total time=   2.5s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=30;, score=0.522 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.03, n_estimators=70;, score=0.532 total time=   4.8s\n",
      "[CV 2/5] END learning_rate=0.3, n_estimators=10;, score=0.511 total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.03, n_estimators=70;, score=0.514 total time=   4.4s\n",
      "[CV 1/5] END learning_rate=0.3, n_estimators=10;, score=0.526 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.3, n_estimators=10;, score=0.509 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.3, n_estimators=10;, score=0.519 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.03, n_estimators=70;, score=0.520 total time=   4.7s\n",
      "[CV 3/5] END learning_rate=0.3, n_estimators=10;, score=0.520 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=50;, score=0.527 total time=   2.9s\n",
      "[CV 5/5] END learning_rate=0.03, n_estimators=70;, score=0.510 total time=   5.0s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=50;, score=0.542 total time=   3.6s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=50;, score=0.535 total time=   3.0s\n",
      "[CV 2/5] END learning_rate=0.03, n_estimators=70;, score=0.514 total time=   5.8s\n",
      "[CV 1/5] END learning_rate=0.3, n_estimators=30;, score=0.550 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.3, n_estimators=30;, score=0.536 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=50;, score=0.532 total time=   3.7s\n",
      "[CV 4/5] END learning_rate=0.3, n_estimators=30;, score=0.546 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.3, n_estimators=30;, score=0.523 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=70;, score=0.536 total time=   4.0s\n",
      "[CV 3/5] END learning_rate=0.3, n_estimators=30;, score=0.546 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=50;, score=0.543 total time=   4.5s\n",
      "[CV 1/5] END learning_rate=0.3, n_estimators=50;, score=0.557 total time=   2.7s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=70;, score=0.549 total time=   5.2s\n",
      "[CV 4/5] END learning_rate=0.3, n_estimators=50;, score=0.549 total time=   2.5s\n",
      "[CV 5/5] END learning_rate=0.3, n_estimators=50;, score=0.535 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=70;, score=0.549 total time=   4.3s\n",
      "[CV 2/5] END learning_rate=0.3, n_estimators=50;, score=0.542 total time=   2.9s\n",
      "[CV 3/5] END learning_rate=0.3, n_estimators=50;, score=0.542 total time=   3.2s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=70;, score=0.535 total time=   4.7s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=70;, score=0.543 total time=   5.2s\n",
      "[CV 2/5] END learning_rate=0.3, n_estimators=70;, score=0.547 total time=   3.6s\n",
      "[CV 1/5] END learning_rate=0.3, n_estimators=70;, score=0.558 total time=   3.7s\n",
      "[CV 3/5] END learning_rate=0.3, n_estimators=70;, score=0.544 total time=   3.5s\n",
      "[CV 5/5] END learning_rate=0.3, n_estimators=70;, score=0.535 total time=   3.2s\n",
      "[CV 4/5] END learning_rate=0.3, n_estimators=70;, score=0.555 total time=   3.3s\n",
      "XGBoost Val Accuracy: 0.5659284497444633\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [10, 30, 50, 70],\n",
    "    'learning_rate' : [0.1, 0.3, 0.1, 0.3, 1.0, 3.0]\n",
    "}\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective=\"multi:softmax\"\n",
    ")\n",
    "gscv2 = GridSearchCV(xgb_clf, param_grid, cv=5, verbose=3, n_jobs=20, scoring=\"accuracy\")\n",
    "gscv2.fit(X_train, y_train)\n",
    "xgb_clf = gscv2.best_estimator_\n",
    "# Test accuracy\n",
    "xgb_test_accuracy = xgb_clf.score(X_val, y_val)\n",
    "print(\"XGBoost Val Accuracy:\", xgb_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=10;, score=0.514 total time=   0.7s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=10;, score=0.505 total time=   0.7s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=10;, score=0.515 total time=   0.9s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=10;, score=0.508 total time=   0.9s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=10;, score=0.495 total time=   1.0s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=10;, score=0.526 total time=   0.7s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=10;, score=0.511 total time=   0.7s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=10;, score=0.519 total time=   0.7s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=30;, score=0.516 total time=   1.7s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=10;, score=0.520 total time=   0.9s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=10;, score=0.509 total time=   0.9s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=30;, score=0.532 total time=   2.5s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=30;, score=0.526 total time=   2.8s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=30;, score=0.522 total time=   2.8s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=50;, score=0.543 total time=   2.8s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=50;, score=0.527 total time=   2.8s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=30;, score=0.517 total time=   2.8s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=30;, score=0.536 total time=   1.7s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=30;, score=0.546 total time=   1.7s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=30;, score=0.550 total time=   2.0s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=30;, score=0.546 total time=   1.7s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=70;, score=0.536 total time=   3.7s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=70;, score=0.543 total time=   3.9s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=30;, score=0.523 total time=   2.1s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=70;, score=0.535 total time=   3.9s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=10;, score=0.515 total time=   0.9s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=50;, score=0.535 total time=   4.3s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=10;, score=0.505 total time=   0.7s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=10;, score=0.508 total time=   0.8s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=50;, score=0.542 total time=   4.5s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=50;, score=0.532 total time=   4.5s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=10;, score=0.495 total time=   0.7s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=50;, score=0.557 total time=   2.6s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=10;, score=0.514 total time=   1.1s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=50;, score=0.535 total time=   2.8s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=70;, score=0.549 total time=   5.7s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=70;, score=0.549 total time=   5.8s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=50;, score=0.542 total time=   3.4s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=50;, score=0.542 total time=   3.4s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=30;, score=0.516 total time=   1.7s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=50;, score=0.549 total time=   3.5s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=30;, score=0.532 total time=   2.1s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=70;, score=0.558 total time=   3.9s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=30;, score=0.522 total time=   2.2s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=30;, score=0.517 total time=   2.3s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=10;, score=0.526 total time=   0.7s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=70;, score=0.544 total time=   4.0s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=10;, score=0.511 total time=   0.7s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=30;, score=0.526 total time=   2.8s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=50;, score=0.527 total time=   2.7s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=10;, score=0.519 total time=   0.7s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=10;, score=0.520 total time=   1.0s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=10;, score=0.509 total time=   0.9s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=50;, score=0.535 total time=   3.1s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=70;, score=0.555 total time=   4.9s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=70;, score=0.547 total time=   5.3s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=70;, score=0.535 total time=   4.9s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=50;, score=0.542 total time=   3.7s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=30;, score=0.550 total time=   1.8s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=30;, score=0.546 total time=   1.8s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=30;, score=0.536 total time=   1.8s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=50;, score=0.543 total time=   4.1s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=50;, score=0.532 total time=   3.4s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=10;, score=0.513 total time=   0.6s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=30;, score=0.523 total time=   2.2s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=30;, score=0.546 total time=   2.3s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=10;, score=0.521 total time=   0.9s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=10;, score=0.520 total time=   1.0s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=70;, score=0.535 total time=   4.0s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=10;, score=0.533 total time=   1.0s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=10;, score=0.506 total time=   1.0s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=50;, score=0.549 total time=   2.9s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=50;, score=0.542 total time=   2.9s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=70;, score=0.536 total time=   4.9s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=50;, score=0.557 total time=   3.5s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=70;, score=0.543 total time=   5.0s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=70;, score=0.549 total time=   5.0s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.1, n_estimators=70;, score=0.549 total time=   5.2s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=30;, score=0.528 total time=   1.5s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=50;, score=0.542 total time=   3.6s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=30;, score=0.522 total time=   2.1s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=30;, score=0.523 total time=   1.9s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=50;, score=0.535 total time=   4.0s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=30;, score=0.521 total time=   1.6s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=70;, score=0.544 total time=   4.0s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=70;, score=0.558 total time=   4.3s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=70;, score=0.535 total time=   3.6s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=30;, score=0.534 total time=   2.5s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=10;, score=0.310 total time=   0.7s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=10;, score=0.307 total time=   0.7s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=10;, score=0.287 total time=   1.0s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=10;, score=0.266 total time=   1.0s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=10;, score=0.304 total time=   0.8s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=70;, score=0.547 total time=   5.1s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=50;, score=0.525 total time=   2.6s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=30;, score=0.239 total time=   1.1s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=50;, score=0.534 total time=   2.6s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=50;, score=0.541 total time=   3.1s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=30;, score=0.198 total time=   1.1s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=30;, score=0.277 total time=   1.3s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=30;, score=0.264 total time=   1.7s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=0.3, n_estimators=70;, score=0.555 total time=   5.4s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=50;, score=0.537 total time=   3.5s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=30;, score=0.348 total time=   1.9s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=50;, score=0.198 total time=   1.4s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=70;, score=0.538 total time=   3.6s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=50;, score=0.239 total time=   1.7s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=70;, score=0.537 total time=   3.6s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=50;, score=0.534 total time=   4.2s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.1, n_estimators=10;, score=0.515 total time=   1.1s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.1, n_estimators=10;, score=0.508 total time=   1.1s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=50;, score=0.264 total time=   2.3s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.1, n_estimators=10;, score=0.514 total time=   1.1s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=70;, score=0.264 total time=   1.7s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=70;, score=0.239 total time=   1.8s\n",
      "[CV 1/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=70;, score=0.531 total time=   4.4s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.1, n_estimators=10;, score=0.505 total time=   0.9s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=50;, score=0.348 total time=   2.3s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=50;, score=0.277 total time=   2.3s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.1, n_estimators=10;, score=0.495 total time=   1.0s\n",
      "[CV 5/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=70;, score=0.198 total time=   1.8s\n",
      "[CV 4/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=70;, score=0.277 total time=   1.9s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=3.0, n_estimators=70;, score=0.348 total time=   2.3s\n",
      "[CV 3/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=70;, score=0.532 total time=   5.3s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.3, n_estimators=10;, score=0.526 total time=   0.7s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.1, n_estimators=30;, score=0.532 total time=   1.8s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.3, n_estimators=10;, score=0.511 total time=   0.7s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.1, n_estimators=30;, score=0.516 total time=   1.9s\n",
      "[CV 2/5] END eval_metric=mlogloss, learning_rate=1.0, n_estimators=70;, score=0.527 total time=   5.8s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.1, n_estimators=30;, score=0.522 total time=   2.1s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.3, n_estimators=10;, score=0.519 total time=   0.7s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.3, n_estimators=10;, score=0.520 total time=   1.0s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.3, n_estimators=10;, score=0.509 total time=   0.7s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.1, n_estimators=30;, score=0.526 total time=   2.8s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.1, n_estimators=30;, score=0.517 total time=   2.7s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.1, n_estimators=50;, score=0.543 total time=   2.8s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.3, n_estimators=30;, score=0.550 total time=   1.6s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.1, n_estimators=50;, score=0.542 total time=   3.3s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.3, n_estimators=30;, score=0.536 total time=   2.1s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.3, n_estimators=30;, score=0.546 total time=   2.0s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.1, n_estimators=50;, score=0.532 total time=   3.6s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.3, n_estimators=30;, score=0.546 total time=   2.2s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.3, n_estimators=30;, score=0.523 total time=   2.1s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.1, n_estimators=70;, score=0.549 total time=   3.8s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.1, n_estimators=50;, score=0.535 total time=   4.1s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.1, n_estimators=10;, score=0.508 total time=   0.7s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.1, n_estimators=10;, score=0.515 total time=   0.8s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.1, n_estimators=50;, score=0.527 total time=   4.7s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.1, n_estimators=10;, score=0.514 total time=   0.9s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.1, n_estimators=10;, score=0.505 total time=   0.7s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.1, n_estimators=10;, score=0.495 total time=   0.7s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.3, n_estimators=50;, score=0.557 total time=   3.1s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.1, n_estimators=70;, score=0.549 total time=   5.0s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.3, n_estimators=50;, score=0.542 total time=   3.3s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.3, n_estimators=50;, score=0.549 total time=   2.8s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.1, n_estimators=70;, score=0.543 total time=   5.2s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.3, n_estimators=50;, score=0.535 total time=   2.9s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.1, n_estimators=70;, score=0.536 total time=   5.5s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.3, n_estimators=50;, score=0.542 total time=   3.9s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.3, n_estimators=70;, score=0.558 total time=   3.4s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.1, n_estimators=30;, score=0.532 total time=   1.8s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.1, n_estimators=30;, score=0.522 total time=   1.7s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.1, n_estimators=70;, score=0.535 total time=   6.1s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.1, n_estimators=30;, score=0.516 total time=   2.1s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.1, n_estimators=30;, score=0.526 total time=   2.2s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.3, n_estimators=10;, score=0.526 total time=   0.7s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.3, n_estimators=10;, score=0.511 total time=   0.7s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.1, n_estimators=30;, score=0.517 total time=   2.5s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.3, n_estimators=10;, score=0.519 total time=   0.7s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.3, n_estimators=10;, score=0.509 total time=   0.7s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.3, n_estimators=70;, score=0.535 total time=   4.1s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.1, n_estimators=50;, score=0.542 total time=   2.8s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.3, n_estimators=10;, score=0.520 total time=   1.1s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.3, n_estimators=70;, score=0.544 total time=   4.4s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.3, n_estimators=70;, score=0.547 total time=   5.2s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.1, n_estimators=50;, score=0.532 total time=   2.8s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.3, n_estimators=30;, score=0.550 total time=   1.7s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.3, n_estimators=30;, score=0.536 total time=   1.7s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.3, n_estimators=70;, score=0.555 total time=   5.4s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.1, n_estimators=50;, score=0.535 total time=   4.1s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.3, n_estimators=30;, score=0.523 total time=   1.7s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.1, n_estimators=50;, score=0.527 total time=   4.5s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.1, n_estimators=70;, score=0.543 total time=   3.9s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.3, n_estimators=30;, score=0.546 total time=   2.3s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.1, n_estimators=50;, score=0.543 total time=   4.6s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=1.0, n_estimators=10;, score=0.513 total time=   0.6s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.3, n_estimators=30;, score=0.546 total time=   2.7s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.1, n_estimators=70;, score=0.535 total time=   3.9s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.3, n_estimators=50;, score=0.542 total time=   2.5s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=1.0, n_estimators=10;, score=0.521 total time=   0.8s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=1.0, n_estimators=10;, score=0.533 total time=   0.7s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=1.0, n_estimators=10;, score=0.520 total time=   1.1s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.3, n_estimators=50;, score=0.557 total time=   2.9s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.1, n_estimators=70;, score=0.536 total time=   5.2s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=1.0, n_estimators=10;, score=0.506 total time=   1.0s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.1, n_estimators=70;, score=0.549 total time=   5.6s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=0.3, n_estimators=70;, score=0.558 total time=   3.4s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.1, n_estimators=70;, score=0.549 total time=   5.8s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.3, n_estimators=50;, score=0.549 total time=   3.9s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.3, n_estimators=50;, score=0.542 total time=   4.1s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=1.0, n_estimators=30;, score=0.528 total time=   2.0s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=1.0, n_estimators=30;, score=0.523 total time=   1.7s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=1.0, n_estimators=30;, score=0.521 total time=   1.6s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=0.3, n_estimators=70;, score=0.547 total time=   3.4s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.3, n_estimators=50;, score=0.535 total time=   4.0s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=1.0, n_estimators=30;, score=0.534 total time=   2.1s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=1.0, n_estimators=30;, score=0.522 total time=   2.6s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=0.3, n_estimators=70;, score=0.544 total time=   3.8s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=3.0, n_estimators=10;, score=0.307 total time=   0.7s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=0.3, n_estimators=70;, score=0.555 total time=   3.9s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=3.0, n_estimators=10;, score=0.287 total time=   1.0s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=3.0, n_estimators=10;, score=0.266 total time=   1.0s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=3.0, n_estimators=10;, score=0.310 total time=   1.1s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=1.0, n_estimators=50;, score=0.537 total time=   2.6s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=3.0, n_estimators=10;, score=0.304 total time=   1.0s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=3.0, n_estimators=30;, score=0.264 total time=   1.4s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=1.0, n_estimators=50;, score=0.541 total time=   3.3s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=1.0, n_estimators=50;, score=0.525 total time=   3.5s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=0.3, n_estimators=70;, score=0.535 total time=   4.7s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=3.0, n_estimators=30;, score=0.277 total time=   1.2s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=3.0, n_estimators=30;, score=0.239 total time=   1.7s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=3.0, n_estimators=50;, score=0.264 total time=   1.4s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=3.0, n_estimators=30;, score=0.198 total time=   1.7s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=3.0, n_estimators=30;, score=0.348 total time=   1.9s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=3.0, n_estimators=50;, score=0.277 total time=   1.6s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=1.0, n_estimators=50;, score=0.534 total time=   3.8s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.1, n_estimators=10;, score=0.508 total time=   0.7s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=1.0, n_estimators=50;, score=0.534 total time=   4.2s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=1.0, n_estimators=70;, score=0.527 total time=   3.8s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=3.0, n_estimators=50;, score=0.239 total time=   2.3s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=1.0, n_estimators=70;, score=0.531 total time=   4.4s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.1, n_estimators=10;, score=0.515 total time=   1.1s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.1, n_estimators=10;, score=0.495 total time=   0.8s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=3.0, n_estimators=50;, score=0.198 total time=   2.3s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=1.0, n_estimators=70;, score=0.538 total time=   4.0s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=3.0, n_estimators=50;, score=0.348 total time=   2.5s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.1, n_estimators=10;, score=0.514 total time=   1.1s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=1.0, n_estimators=70;, score=0.537 total time=   3.9s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.1, n_estimators=10;, score=0.505 total time=   1.1s\n",
      "[CV 5/5] END eval_metric=merror, learning_rate=3.0, n_estimators=70;, score=0.198 total time=   1.8s\n",
      "[CV 2/5] END eval_metric=merror, learning_rate=3.0, n_estimators=70;, score=0.239 total time=   2.0s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=3.0, n_estimators=70;, score=0.348 total time=   1.9s\n",
      "[CV 1/5] END eval_metric=merror, learning_rate=3.0, n_estimators=70;, score=0.264 total time=   2.6s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.3, n_estimators=10;, score=0.511 total time=   0.7s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.3, n_estimators=10;, score=0.526 total time=   0.7s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.1, n_estimators=30;, score=0.516 total time=   1.7s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.1, n_estimators=30;, score=0.532 total time=   2.1s\n",
      "[CV 3/5] END eval_metric=merror, learning_rate=1.0, n_estimators=70;, score=0.532 total time=   5.3s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.3, n_estimators=10;, score=0.520 total time=   0.7s\n",
      "[CV 4/5] END eval_metric=merror, learning_rate=3.0, n_estimators=70;, score=0.277 total time=   3.1s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.3, n_estimators=10;, score=0.509 total time=   0.7s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.3, n_estimators=10;, score=0.519 total time=   0.7s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.1, n_estimators=30;, score=0.522 total time=   2.1s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.1, n_estimators=30;, score=0.526 total time=   2.7s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.1, n_estimators=30;, score=0.517 total time=   2.8s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.1, n_estimators=50;, score=0.542 total time=   2.9s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.3, n_estimators=30;, score=0.546 total time=   1.7s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.3, n_estimators=30;, score=0.536 total time=   1.9s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.3, n_estimators=30;, score=0.546 total time=   2.1s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.3, n_estimators=30;, score=0.523 total time=   2.0s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.1, n_estimators=50;, score=0.543 total time=   3.8s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.3, n_estimators=30;, score=0.550 total time=   2.5s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.1, n_estimators=50;, score=0.532 total time=   3.7s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.1, n_estimators=50;, score=0.527 total time=   4.2s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.3, n_estimators=50;, score=0.557 total time=   2.5s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.1, n_estimators=70;, score=0.535 total time=   4.0s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.3, n_estimators=50;, score=0.542 total time=   2.6s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.1, n_estimators=50;, score=0.535 total time=   4.6s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.1, n_estimators=10;, score=0.508 total time=   0.8s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.1, n_estimators=10;, score=0.515 total time=   0.9s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.1, n_estimators=70;, score=0.536 total time=   4.7s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.1, n_estimators=70;, score=0.549 total time=   4.7s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.1, n_estimators=10;, score=0.514 total time=   1.1s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.3, n_estimators=50;, score=0.542 total time=   3.2s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.1, n_estimators=10;, score=0.495 total time=   0.7s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.1, n_estimators=10;, score=0.505 total time=   1.0s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.1, n_estimators=70;, score=0.543 total time=   5.9s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.1, n_estimators=30;, score=0.532 total time=   1.8s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.1, n_estimators=30;, score=0.516 total time=   1.7s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.1, n_estimators=70;, score=0.549 total time=   5.9s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.1, n_estimators=30;, score=0.526 total time=   1.8s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.3, n_estimators=70;, score=0.558 total time=   3.9s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.3, n_estimators=50;, score=0.535 total time=   4.1s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.3, n_estimators=50;, score=0.549 total time=   4.1s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.3, n_estimators=70;, score=0.547 total time=   3.9s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.3, n_estimators=10;, score=0.526 total time=   0.7s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.3, n_estimators=70;, score=0.555 total time=   3.8s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.1, n_estimators=30;, score=0.522 total time=   2.8s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.1, n_estimators=30;, score=0.517 total time=   2.7s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.3, n_estimators=10;, score=0.511 total time=   0.8s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.3, n_estimators=10;, score=0.519 total time=   1.0s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.3, n_estimators=10;, score=0.520 total time=   1.1s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.1, n_estimators=50;, score=0.532 total time=   2.9s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.3, n_estimators=70;, score=0.535 total time=   4.2s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.3, n_estimators=10;, score=0.509 total time=   1.1s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.3, n_estimators=70;, score=0.544 total time=   5.1s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.1, n_estimators=50;, score=0.542 total time=   3.8s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.1, n_estimators=50;, score=0.535 total time=   3.8s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.1, n_estimators=50;, score=0.527 total time=   4.0s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.1, n_estimators=50;, score=0.543 total time=   4.1s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.1, n_estimators=70;, score=0.549 total time=   3.9s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.3, n_estimators=30;, score=0.536 total time=   2.2s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.3, n_estimators=30;, score=0.523 total time=   2.1s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.3, n_estimators=30;, score=0.550 total time=   2.5s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.1, n_estimators=70;, score=0.536 total time=   3.8s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=1.0, n_estimators=10;, score=0.513 total time=   0.8s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.3, n_estimators=30;, score=0.546 total time=   2.7s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.3, n_estimators=30;, score=0.546 total time=   2.7s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=1.0, n_estimators=10;, score=0.520 total time=   0.7s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.3, n_estimators=50;, score=0.557 total time=   2.6s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.1, n_estimators=70;, score=0.549 total time=   4.2s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=1.0, n_estimators=10;, score=0.506 total time=   0.7s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.1, n_estimators=70;, score=0.543 total time=   4.5s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=1.0, n_estimators=10;, score=0.533 total time=   1.0s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=1.0, n_estimators=10;, score=0.521 total time=   1.0s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.3, n_estimators=50;, score=0.542 total time=   3.0s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.3, n_estimators=50;, score=0.542 total time=   3.3s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.3, n_estimators=50;, score=0.535 total time=   3.0s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.1, n_estimators=70;, score=0.535 total time=   5.6s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=1.0, n_estimators=30;, score=0.521 total time=   1.6s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.3, n_estimators=50;, score=0.549 total time=   4.1s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=0.3, n_estimators=70;, score=0.547 total time=   3.4s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=1.0, n_estimators=30;, score=0.528 total time=   2.1s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=1.0, n_estimators=30;, score=0.523 total time=   2.0s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=0.3, n_estimators=70;, score=0.535 total time=   3.3s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=1.0, n_estimators=30;, score=0.534 total time=   2.6s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=1.0, n_estimators=30;, score=0.522 total time=   2.6s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=3.0, n_estimators=10;, score=0.310 total time=   0.7s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=3.0, n_estimators=10;, score=0.266 total time=   0.8s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=3.0, n_estimators=10;, score=0.307 total time=   0.8s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=3.0, n_estimators=10;, score=0.287 total time=   1.1s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=1.0, n_estimators=50;, score=0.525 total time=   2.6s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=1.0, n_estimators=50;, score=0.541 total time=   2.7s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=3.0, n_estimators=10;, score=0.304 total time=   0.9s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=1.0, n_estimators=50;, score=0.537 total time=   3.0s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=0.3, n_estimators=70;, score=0.558 total time=   5.1s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=0.3, n_estimators=70;, score=0.555 total time=   5.1s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=1.0, n_estimators=50;, score=0.534 total time=   3.4s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=3.0, n_estimators=30;, score=0.277 total time=   1.3s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=3.0, n_estimators=30;, score=0.198 total time=   1.1s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=1.0, n_estimators=50;, score=0.534 total time=   3.4s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=0.3, n_estimators=70;, score=0.544 total time=   5.5s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=3.0, n_estimators=30;, score=0.264 total time=   1.7s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=3.0, n_estimators=30;, score=0.348 total time=   1.7s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=3.0, n_estimators=30;, score=0.239 total time=   1.7s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=3.0, n_estimators=50;, score=0.198 total time=   1.6s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=3.0, n_estimators=50;, score=0.264 total time=   1.8s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=3.0, n_estimators=50;, score=0.239 total time=   1.9s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=1.0, n_estimators=70;, score=0.527 total time=   4.1s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=1.0, n_estimators=70;, score=0.532 total time=   4.0s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=3.0, n_estimators=50;, score=0.277 total time=   2.0s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=3.0, n_estimators=70;, score=0.264 total time=   1.8s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=3.0, n_estimators=50;, score=0.348 total time=   2.2s\n",
      "[CV 2/5] END eval_metric=auc, learning_rate=3.0, n_estimators=70;, score=0.239 total time=   1.7s\n",
      "[CV 1/5] END eval_metric=auc, learning_rate=1.0, n_estimators=70;, score=0.531 total time=   4.9s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=1.0, n_estimators=70;, score=0.538 total time=   4.1s\n",
      "[CV 3/5] END eval_metric=auc, learning_rate=3.0, n_estimators=70;, score=0.348 total time=   1.8s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=3.0, n_estimators=70;, score=0.198 total time=   1.8s\n",
      "[CV 5/5] END eval_metric=auc, learning_rate=1.0, n_estimators=70;, score=0.537 total time=   4.2s\n",
      "[CV 4/5] END eval_metric=auc, learning_rate=3.0, n_estimators=70;, score=0.277 total time=   2.0s\n",
      "XGBoost Val Accuracy: 0.5659284497444633\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators' : [10, 30, 50, 70],\n",
    "    'learning_rate' : [0.1, 0.3, 0.1, 0.3, 1.0, 3.0], \n",
    "    'eval_metric' : [\"mlogloss\", \"merror\", \"auc\"]\n",
    "}\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective=\"multi:softmax\"\n",
    ")\n",
    "gscv2 = GridSearchCV(xgb_clf, param_grid, cv=5, verbose=3, n_jobs=20, scoring=\"accuracy\")\n",
    "gscv2.fit(X_train, y_train)\n",
    "xgb_clf = gscv2.best_estimator_\n",
    "# Test accuracy\n",
    "xgb_test_accuracy = xgb_clf.score(X_val, y_val)\n",
    "print(\"XGBoost Val Accuracy:\", xgb_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_input = X_test.to_numpy().astype(float)\n",
    "X_test_input = scaler.transform(X_test_input)\n",
    "test_predictions = xgb_clf.predict(X_test_input)\n",
    "\n",
    "submission = {\n",
    "    \"id\" : list(range(len(test_predictions))), \n",
    "    \"price\" : list(test_predictions.astype(float).astype(int).astype(float))\n",
    "}\n",
    "\n",
    "submission = pd.DataFrame.from_dict(submission)\n",
    "\n",
    "submission.to_csv(os.path.join(\"submissions/\", \"bahng_xgb2.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
