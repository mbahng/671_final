{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa5e1b26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from preprocess import preprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(\"data\", \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(\"data\", \"test.csv\"))\n",
    "train_data.dropna(inplace=True)\n",
    "X, y = train_data.drop([\"price\"], axis=1), train_data[\"price\"]\n",
    "y = y.astype(int)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_test = test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a826500-9516-44b3-8b2b-f7ce22159e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cea5bc4a-c48c-47f6-8ce8-6245c56ece0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END ..................................., score=0.624 total time=  29.3s\n",
      "[CV 4/5] END ..................................., score=0.641 total time=  29.3s\n",
      "[CV 2/5] END ..................................., score=0.666 total time=  29.5s\n",
      "[CV 3/5] END ..................................., score=0.637 total time=  29.6s\n",
      "[CV 1/5] END ..................................., score=0.643 total time=  29.8s\n",
      "Best Parameter Estimates: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/muchang/Desktop/other/671_final/random_forest.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi3t/home/muchang/Desktop/other/671_final/random_forest.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest Parameter Estimates:\u001b[39m\u001b[39m'\u001b[39m, best_rf\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mget_params())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi3t/home/muchang/Desktop/other/671_final/random_forest.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(best_rf\u001b[39m.\u001b[39mpredict(X_val))\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bi3t/home/muchang/Desktop/other/671_final/random_forest.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_val, y_pred, digits\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/cs/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/cs/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2545\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2410\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m   2411\u001b[0m     {\n\u001b[1;32m   2412\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2436\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2437\u001b[0m ):\n\u001b[1;32m   2438\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2439\u001b[0m \n\u001b[1;32m   2440\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2542\u001b[0m \u001b[39m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2543\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2545\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   2547\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2548\u001b[0m         labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs/lib/python3.10/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and multiclass targets"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "hyperparameters = {\n",
    "    # 'n_estimators': [300, 400],\n",
    "    # 'class_weight' : [None], \n",
    "    # 'max_depth': [20],\n",
    "    # 'min_samples_split': [5, 10],\n",
    "    # 'min_samples_leaf': [1, 2, 4],\n",
    "    # 'max_features': ['log2', 'sqrt'], \n",
    "    # 'criterion': [\"gini\"]\n",
    "}\n",
    "# clf = GridSearchCV(rf, hyperparameters, cv=5, verbose=3, n_jobs=20, scoring=\"accuracy\")\n",
    "clf = GridSearchCV(rf, hyperparameters, cv=5, verbose=3, n_jobs=20)\n",
    "best_rf = clf.fit(X_train,y_train)\n",
    "\n",
    "print('Best Parameter Estimates:', best_rf.best_estimator_.get_params())\n",
    "\n",
    "y_pred = np.log(best_rf.predict(X_val)).astype(int)\n",
    "print(classification_report(np.log(y_val).astype(int), y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ffae5a9-20d8-489a-8398-8ee2d7d8a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_input = X_test.to_numpy().astype(float)\n",
    "X_test_input = scaler.transform(X_test_input)\n",
    "test_predictions = best_rf.predict(X_test_input)\n",
    "\n",
    "submission = {\n",
    "    \"id\" : list(range(len(test_predictions))), \n",
    "    \"price\" : list(test_predictions.astype(float))\n",
    "}\n",
    "\n",
    "submission = pd.DataFrame.from_dict(submission)\n",
    "\n",
    "submission.to_csv(os.path.join(\"submissions/\", \"bahng_rf6.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Validation Accuracy: 0.5706984667802385\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators' : [100, 200, 300, 400, 500, 1000],\n",
    "#     'learning_rate' : [0.1, 0.5, 1.0], \n",
    "#     'algorithm' : ['SAMME.R']\n",
    "# }\n",
    "\n",
    "# # Adaboost with DecisionTree as base estimator\n",
    "# ada_clf = AdaBoostClassifier(\n",
    "#     estimator=DecisionTreeClassifier(max_depth = 5)\n",
    "# )\n",
    "\n",
    "# gscv = GridSearchCV(ada_clf, param_grid, cv=5, verbose=3, n_jobs=20, scoring=\"accuracy\")\n",
    "# gscv.fit(X_train, y_train)\n",
    "# ada_clf = gscv.best_estimator_\n",
    "# ada_val_accuracy = ada_clf.score(X_val, y_val)\n",
    "# print(\"Adaboost Validation Accuracy:\", ada_val_accuracy)\n",
    "\n",
    "# estimators = [('ridge', DecisionTreeClassifier()),\n",
    "#               ('lasso', LinearSVC()),\n",
    "#               ('knr', KNeighborsClassifier(n_neighbors=20,\n",
    "                                        #   metric='euclidean'))]\n",
    "\n",
    "\n",
    "reg = AdaBoostClassifier(\n",
    "estimator=RandomForestClassifier(), n_estimators=50)\n",
    "\n",
    "# reg = StackingClassifier(\n",
    "    # estimators=estimators,\n",
    "    # final_estimator=final_estimator)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "ada_val_accuracy = reg.score(X_val, y_val)\n",
    "print(\"Adaboost Validation Accuracy:\", ada_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_input = X_test.to_numpy().astype(float)\n",
    "X_test_input = scaler.transform(X_test_input)\n",
    "test_predictions = reg.predict(X_test_input)\n",
    "\n",
    "submission = {\n",
    "    \"id\" : list(range(len(test_predictions))), \n",
    "    \"price\" : list(test_predictions.astype(float).astype(int).astype(float))\n",
    "}\n",
    "\n",
    "submission = pd.DataFrame.from_dict(submission)\n",
    "\n",
    "submission.to_csv(os.path.join(\"submissions/\", \"bahng_ada2.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
